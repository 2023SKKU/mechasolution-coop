{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTmSNX1EQuC2"
      },
      "outputs": [],
      "source": [
        "!pip install bertopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVIKMtb2Q15d"
      },
      "outputs": [],
      "source": [
        "!pip install bertopic[visualization]\n",
        "!pip install plotly==5.15.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_otRd7vqY1oc"
      },
      "outputs": [],
      "source": [
        "!pip install konlpy\n",
        "!pip install mecab-python\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQFgFWuYBLd_"
      },
      "outputs": [],
      "source": [
        "!pip install octis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCsr3qs5TAAN"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from konlpy.tag import Mecab\n",
        "from bertopic import BERTopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpl6i-ggm9Hr"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mKOGXYTT75W"
      },
      "outputs": [],
      "source": [
        "!wget -O ns_reviewss.csv https://www.dropbox.com/s/a2te6ou3mz21i78/ns_reviewss_positive_temp.csv?dl=0\n",
        "!wget -O ns_reviewss2.csv https://www.dropbox.com/s/ea8kgugiffgw7yp/ns_reviewss2.csv?dl=0\n",
        "!wget -O stopwords.txt https://www.dropbox.com/s/7nb3uhaj08aamiw/stopwords.txt?dl=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G5hFKZFTKFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "047f4f25-9969-4dac-e67d-06b7f4e8cb21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['은', '는', '이', '가', '네요', '합니다', '아요', '아주', '어요', '으면', '아용', '는데', '해졌', '해서', '아오', '지나', '아요', '그런지', '중간', '어야', ';;', '감사', '아서', '아직', '다음', '매번', '백서', '모르', '구매', '엄마', '저요', '조아', '져요', '30', '벌써', '이거', '진작', '그랬', '샀으면', '!', '!!', '!!!', '!!!!', '!!!!!', '!!!!!!', '!!!!!!!', '이제야', '씁니다', '오우', '으면', '게여', '~', '^', '~^^', '요오', '지만', '납니다', '아니', '광고', '삼림', '인데', '아서', 'ㅎㅎ', 'ㅎ', 'ㅎㅎㅎ', 'ㅎㅎㅎㅎ', 'ㅎㅎㅎㅎㅎ', 'ㅎㅎㅎㅎㅎㅎ', '해서', '보다', '한데', 'ㅋ', 'ㅋㅋ', 'ㅋㅋㅋ', 'ㅋㅋㅋㅋ', 'ㅋㅋㅋㅋㅋ', 'ㅋㅋㅋㅋㅋㅋ', 'ㅋㅋㅋㅋㅋㅋㅋ', '샤샤', '놔요', '께요', '예요', '여러', '~~~~~~~', '후기', '아서', '보고', '습니다', '입니다', '욕ㅋ', '쓸께요', '쓸게요', '할게요', '항상', '처음', '요조', '기그', '졋어요', '아우', '정하', '요요', '세여', '마니', '탁조', '<br>', '<em>', '조기', '미닉스']\n",
            "르무통 메이트 발 편한 썸머울 쾌적한 데일리 운동화\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "195100    None\n",
              "195101    None\n",
              "195103    None\n",
              "195104    None\n",
              "195106    None\n",
              "          ... \n",
              "208575    None\n",
              "208576    None\n",
              "208577    None\n",
              "208578    None\n",
              "208579    None\n",
              "Name: content, Length: 11803, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('ns_reviewss.csv')\n",
        "documents = []\n",
        "\n",
        "stopwords = []\n",
        "\n",
        "f = open('stopwords.txt', 'r', encoding='utf-8')\n",
        "while True:\n",
        "    line = f.readline()\n",
        "    if not line: break\n",
        "    stopwords.append(line.rstrip())\n",
        "\n",
        "print(stopwords)\n",
        "\n",
        "mecab = Mecab()\n",
        "def get_content(x):\n",
        "    word_tokens = mecab.pos(x)\n",
        "    result = []\n",
        "    for w, p in word_tokens:\n",
        "        if len(w) <= 1 or w in stopwords:\n",
        "            continue\n",
        "        if p[:3] == 'NNG' or p[:3] == 'NNP' or p[:2] == 'VV' or p[:2] == 'VA':\n",
        "\n",
        "            result.append(w)\n",
        "    if len(result) > 1:\n",
        "        documents.append(' '.join(result))\n",
        "df_seje = df[df['product_category'] == '슬립온']\n",
        "df_seje = df_seje[df_seje['star_rating'] == 5]\n",
        "p_li = df_seje.groupby('productName').count().index.to_list()\n",
        "print(p_li[0])\n",
        "df_seje[df['productName'] == p_li[0]]['content'].apply(get_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS3yTWGdUPAc",
        "outputId": "23c6458a-cddb-4abe-f5b7-78554b084b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['직업 출근 배송 나왔 가볍 완벽 정도 솜이불 온몸 싸매 침대 누운 느낌 알긴 녹아내리 바닥 요즘 놀이터 맨발 느낌 여름 이번 여름 지내 평소 나온 신발 사람 사이즈 걱정 발등 그런가 사이즈 크기 손가락 들어가 정도 정도 운동 부분 발목 불편 발꿈치 맞추 발가락 앞부분 정도 정도 신발 발등 전력 질주 이상 벗겨질 발가락 신기 편할 색상 진한 청색 코디 어울릴 만족 신발 디자인 빠른 배송 오늘 열일', '짝꿍 생일 선물 무통 일본 여행 짝꿍 오사카 무통 여성 짝꿍 체구 커요 최근 여행 아프 발볼 사람 신발 여행 다녔 디자인 스니커즈 디자인 어울려요 재질 무게 보통 스니커즈 천보다 두껍 느낌 그럼에도 신발 가벼워 발볼 짝꿍 기발 발볼 발등 편합니다 착화 짝꿍 편하 아껴', '추가 하루 신고 출퇴근 신고 다니 신발 헐떡이 느낌 신발 편하 느낌 이상 단위 만들 주문 교환 만족 평소 단위 주문 디자인 귀엽 무게 가볍 신발 넓혀서 느낌 느낌 바지 스키니 엄지발가락 신발 앞코 고민 가로수길 매장 신어 신발 넓히 박스 꺼낸 상태 신어 여유 자연 들어가 편하 교환 기간 교환 신청 만약 교환 교환 교환 교환 신청 답변 치수 답변 확신 오늘 교환 배송 도착 편하 들어가 신고 집안 다니 편해요 발볼 치수 편하 사이즈 양말 수준 내일 신고 다닐 다녔 가격 편하 신발', '택배 무통 첫인상 호감 플라스틱 종이 박스 포장 환경 신경 기업 생각 신발 생각 생겼 신발 들어가 입구 부분 갈색 못생겼 느꼈 왕발 보였 생각 바닥 발등 들어가 부분 느껴졌 착화 반품 생각 반품 후회 사진 일반 스니커즈 나오 신발 모양 맞춰 편해요 바닥 받쳐 느낌 발목 무리 기분 단점 신발 밑창 들어오 밑창 마르 만족 색상 의사 신발 신고 발목 통증 느낀', '크롭 앨범 올리 상품 이미지 올리 첨부 발길 발볼 족저 근막염 타입 평생 만족 신발 도전 발목 무너지 무릎 느낌 편하 스케쳐 신발 접하 인생 신발 디자인 무통 접했 패션 구하 생각 할인 이벤트 소식 기다렸 신발 평소 신발 스케쳐 발볼 편하 자체 생각 발등 조여서 느낌 헐겁 다녀서 낯선 사람 도통 고민 드려 친절 편의 선택 여유있 감싸 다닐 착용감 마음 발등 조여서 피로 부담 편안 이번 기회 발길 발볼 발등 극악 형태 아쉬운 이상 오른쪽 신발 커서 느낌 신발 당겨 도통 이유 신발 발길 확인 문제 그러 신발 머리 고민 결정 어려웠 아쉽 쉬워요 신발 얘기 스케쳐 신발 그레이 베이지 화이트 패션 원했 생각 귀여운 디자인 마음 신발 티즈 털색 화이트 어울렸 괜찮 재질 어울리 원단 메리노 울이 기대 신발 기준 디자인 가격 발볼 염려 발볼 발볼 걱정 필요 쿠션 기준 설명 스케쳐 워크 맥스 사이 맥스 안정 무통 워크 아웃 두껍 탄력 부드럽 안정 무릎 걱정 선택 마루 소리 미끄럼 걱정 밑창 사진 걱정 사이즈 고민 시간 동안 뒤져 고민 스케쳐 신발 니트 재질 방수 패션 튕겨낸다 신발 아까워서 비올 할인 덕분 만족 소비 루틴 정해져 다녔 실착 대한 사용 디자인 화이트 연한 베이지 색감 신발 나왔 바람']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10891/10891 [00:00<00:00, 1063764.26it/s]\n"
          ]
        }
      ],
      "source": [
        "print(documents[:5])\n",
        "preprocessed_documents = []\n",
        "\n",
        "for line in tqdm(documents):\n",
        "  # 빈 문자열이거나 숫자로만 이루어진 줄은 제외\n",
        "  if line and not line.replace(' ', '').isdecimal():\n",
        "    preprocessed_documents.append(line)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr2187fSV34J"
      },
      "outputs": [],
      "source": [
        "from bertopic.representation import KeyBERTInspired\n",
        "from bertopic.vectorizers import ClassTfidfTransformer\n",
        "ctfidf_model = ClassTfidfTransformer(bm25_weighting=True, reduce_frequent_words=True)\n",
        "\n",
        "\n",
        "representation_model = KeyBERTInspired()\n",
        "\n",
        "class CustomTokenizer:\n",
        "    def __init__(self, tagger):\n",
        "        self.tagger = tagger\n",
        "    def __call__(self, sent):\n",
        "        # sent = sent[:1000000]\n",
        "        word_tokens = sent.split(' ')\n",
        "        result = []\n",
        "        for w in word_tokens:\n",
        "            if len(w) >= 1 and not w in stopwords:\n",
        "                result.append(w)\n",
        "\n",
        "        return result\n",
        "\n",
        "custom_tokenizer = CustomTokenizer(Mecab())\n",
        "vectorizer = CountVectorizer(tokenizer=custom_tokenizer, max_features=3000)\n",
        "\n",
        "seed_li = [['디자인', '색상', '색깔', '색', '모양'],\n",
        "           ['깨끗', '청소', '세정', '세척', '깔끔'],\n",
        "           ['선물', '부모님', '부모', '엄마', '아빠',],\n",
        "           ['무게', '가볍', '들다', '편하다'],\n",
        "           ['배송', '빠른', '빠르', '빨라요', '빠릅니다']]\n",
        "\n",
        "n_topic = 3\n",
        "model = BERTopic(embedding_model=\"beomi/KcELECTRA-base-v2022\",\n",
        "                 representation_model=representation_model,\n",
        "                 ctfidf_model=ctfidf_model,\n",
        "                 seed_topic_list=seed_li,\n",
        "                 vectorizer_model=vectorizer,\n",
        "                 nr_topics=n_topic,\n",
        "                 top_n_words=10,\n",
        "                 calculate_probabilities=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6pVQp6rX7Ss",
        "outputId": "1b0c46ad-dce2-4b3c-ea68-29e6af1ffdde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/beomi_KcELECTRA-base-v2022. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/beomi_KcELECTRA-base-v2022 were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "topics, probs = model.fit_transform(preprocessed_documents)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = 0\n",
        "for k in range(n_topic-1):\n",
        "    words = [w for w, p in model.get_topic(k)]\n",
        "\n",
        "    for i in range(9):\n",
        "        for j in range(i+1, 10):\n",
        "            res += cos_sim(ft.get_word_vector(words[i]), ft.get_word_vector(words[j]))"
      ],
      "metadata": {
        "id": "Ssj9Mxayb2iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(res/2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rPnXP5lcBt2",
        "outputId": "a3b3f1e1-ab3f-4398-fe12-30b469176dc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.921251282095909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7eu1JyzDlH_"
      },
      "outputs": [],
      "source": [
        "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
        "npmi = Coherence(texts=[w.split() for w in preprocessed_documents])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "s9q8ug5OQeqr",
        "outputId": "13566eb0-b14a-499f-b859-563fd4c5d5f8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-97974c2b045c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/_bertopic.py\u001b[0m in \u001b[0;36mvisualize_topics\u001b[0;34m(self, topics, top_n_topics, custom_labels, title, width, height)\u001b[0m\n\u001b[1;32m   2191\u001b[0m         \"\"\"\n\u001b[1;32m   2192\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2193\u001b[0;31m         return plotting.visualize_topics(self,\n\u001b[0m\u001b[1;32m   2194\u001b[0m                                          \u001b[0mtopics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2195\u001b[0m                                          \u001b[0mtop_n_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_n_topics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/plotting/_topics.py\u001b[0m in \u001b[0;36mvisualize_topics\u001b[0;34m(topic_model, topics, top_n_topics, custom_labels, title, width, height)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic_embeddings_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic_embeddings_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUMAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cosine'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_tf_idf_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2770\u001b[0m             \u001b[0mLocal\u001b[0m \u001b[0mradii\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mpoints\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtransformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2771\u001b[0m         \"\"\"\n\u001b[0;32m-> 2772\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2773\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2774\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2683\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2684\u001b[0;31m             self.embedding_, aux_data = self._fit_embed_data(\n\u001b[0m\u001b[1;32m   2685\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36m_fit_embed_data\u001b[0;34m(self, X, n_epochs, init, random_state)\u001b[0m\n\u001b[1;32m   2715\u001b[0m         \u001b[0mreplaced\u001b[0m \u001b[0mby\u001b[0m \u001b[0msubclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2716\u001b[0m         \"\"\"\n\u001b[0;32m-> 2717\u001b[0;31m         return simplicial_set_embedding(\n\u001b[0m\u001b[1;32m   2718\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2719\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36msimplicial_set_embedding\u001b[0;34m(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, densmap, densmap_kwds, output_dens, output_metric, output_metric_kwds, euclidean_output, parallel, verbose, tqdm_kwds)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     38\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     39\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n",
            "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
          ]
        }
      ],
      "source": [
        "model.visualize_topics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEDgfEm2AEJ9",
        "outputId": "c85edf15-d3b3-4046-a6dc-8f03c7a3996f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({-1: 6188, 0: 4631, 1: 72})\n"
          ]
        }
      ],
      "source": [
        "print(model.topic_sizes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKqvHkTLr2bq"
      },
      "outputs": [],
      "source": [
        "topic_idxs = []\n",
        "while model.topic_sizes_[0] / model.topic_sizes_[1] >= 10:\n",
        "    n_topic += 1\n",
        "    print('topic number increased')\n",
        "    model = BERTopic(embedding_model=\"beomi/KcELECTRA-base-v2022\",\n",
        "                 vectorizer_model=vectorizer,\n",
        "                 nr_topics=n_topic,\n",
        "                 top_n_words=10,\n",
        "                 calculate_probabilities=True)\n",
        "\n",
        "    topics, probs = model.fit_transform(preprocessed_documents)\n",
        "    print(model.topic_sizes_)\n",
        "\n",
        "st = 0\n",
        "for i in range(n_topic-1):\n",
        "    keyword = []\n",
        "    for w, p in model.get_topic(i):\n",
        "        keyword.append(w)\n",
        "    if not '배송' in keyword:\n",
        "        if len(topic_idxs) == 0:\n",
        "            st = i\n",
        "            print(st)\n",
        "            topic_idxs.append(i)\n",
        "        elif model.topic_sizes_[st] / model.topic_sizes_[i] <= 5:\n",
        "            topic_idxs.append(i)\n",
        "        else:\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHQpfMgxRzgx",
        "outputId": "cb83c706-c50a-41e1-ac6a-a4aa78751779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 번째 토픽 : [('발볼', 0.59288704), ('신어', 0.5581603), ('가벼워서', 0.5531374), ('반신반의', 0.5510247), ('발편', 0.55066293), ('편해요', 0.543149), ('편합니다', 0.5410656), ('지외', 0.5276013), ('족저', 0.5175528), ('걸어도', 0.51423866)]\n",
            "1 번째 토픽 : [('색상', 0.6566635), ('가족', 0.63845116), ('어머니', 0.6074452), ('운동화', 0.59730685), ('만족', 0.5968543), ('아이', 0.579113), ('빠른', 0.55603254), ('사진', 0.54752403), ('쿠션', 0.5467197), ('착용', 0.53395337)]\n",
            "topic 1: 발볼 신어 가벼워서 반신반의 발편 편해요 편합니다 지외 족저 걸어도 \n",
            "topic 2: 색상 가족 어머니 운동화 만족 아이 빠른 사진 쿠션 착용 \n"
          ]
        }
      ],
      "source": [
        "for i in range(0, n_topic-1):\n",
        "  print(i,'번째 토픽 :', model.get_topic(i))\n",
        "for i in range(0, n_topic-1):\n",
        "  print('topic {}:'.format(i+1), end=' ')\n",
        "  for w, p in model.get_topic(i):\n",
        "    print(w, end=' ')\n",
        "  print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "I-tVw3P52Z09",
        "outputId": "25775874-0152-46f0-bf50-37ff36587353"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Topic  Count               Name  \\\n",
              "0     -1   6139   -1_편했_발볼_가벼워서_신어   \n",
              "1      0   4683  0_발볼_신어_가벼워서_반신반의   \n",
              "2      1     69    1_색상_가족_어머니_운동화   \n",
              "\n",
              "                                     Representation  \\\n",
              "0    [편했, 발볼, 가벼워서, 신어, 편해요, 편합니다, 푹신, 걸어도, 발편, 지외]   \n",
              "1  [발볼, 신어, 가벼워서, 반신반의, 발편, 편해요, 편합니다, 지외, 족저, 걸어도]   \n",
              "2        [색상, 가족, 어머니, 운동화, 만족, 아이, 빠른, 사진, 쿠션, 착용]   \n",
              "\n",
              "                                 Representative_Docs  \n",
              "0  [아파 지인 추천 무통 신고 보이 편하 아프 발볼 디자인 예쁘 발볼 편안 신발 무통...  \n",
              "1  [평소 느낌 신발 편하 편하 가벼워 신고 편하 발볼 발등 신발 신고 불편 무통 편하...  \n",
              "2                              [빠른 배송, 빠른 배송, 빠른 배송]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e440d9a2-95c0-4378-aa27-154680d2a50d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Count</th>\n",
              "      <th>Name</th>\n",
              "      <th>Representation</th>\n",
              "      <th>Representative_Docs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>6139</td>\n",
              "      <td>-1_편했_발볼_가벼워서_신어</td>\n",
              "      <td>[편했, 발볼, 가벼워서, 신어, 편해요, 편합니다, 푹신, 걸어도, 발편, 지외]</td>\n",
              "      <td>[아파 지인 추천 무통 신고 보이 편하 아프 발볼 디자인 예쁘 발볼 편안 신발 무통...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>4683</td>\n",
              "      <td>0_발볼_신어_가벼워서_반신반의</td>\n",
              "      <td>[발볼, 신어, 가벼워서, 반신반의, 발편, 편해요, 편합니다, 지외, 족저, 걸어도]</td>\n",
              "      <td>[평소 느낌 신발 편하 편하 가벼워 신고 편하 발볼 발등 신발 신고 불편 무통 편하...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>69</td>\n",
              "      <td>1_색상_가족_어머니_운동화</td>\n",
              "      <td>[색상, 가족, 어머니, 운동화, 만족, 아이, 빠른, 사진, 쿠션, 착용]</td>\n",
              "      <td>[빠른 배송, 빠른 배송, 빠른 배송]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e440d9a2-95c0-4378-aa27-154680d2a50d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e440d9a2-95c0-4378-aa27-154680d2a50d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e440d9a2-95c0-4378-aa27-154680d2a50d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "model.get_topic_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Arg8QJpOkecX"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCvS_cEwjAoe",
        "outputId": "6eb83d77-8c94-4409-f30f-a9f5886f6b1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "제거 곰팡이 박멸 살균 우수 품질 완전 청소   청소 화장실 욕실 상품 번창 사업 순삭 락스 냄새 이용 효과 기대 만족 최고 적극 추천 완전 대박 사용 구수\n",
            "\n",
            "1. 위에 있는 단어들은 '세제' 상품의 리뷰에서 추출한 키워드들이다.\n",
            "2. 저 키워드들을 활용해서 이 상품의 장점을 한 문장으로 설명한다.\n",
            "3. 모든 키워드를 쓸 필요 없이, 자연스러운 간결한 문장 하나로 완성한다.\n",
            "4. 한글로 쓴다.\n",
            "5. 객관적인 시선으로 쓴다.\n",
            "\n",
            "이 상품은 곰팡이를 제거하고 박멸하여 욕실과 화장실을 완전히 청소할 수 있는 우수한 품질을 가지고 있습니다.\n"
          ]
        }
      ],
      "source": [
        "# -*coding: utf-8 -*\n",
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = ''\n",
        "prompt = '''\n",
        "\n",
        "1. 위에 있는 단어들은 '{}' 상품의 리뷰에서 추출한 키워드들이다.\n",
        "2. 저 키워드들을 활용해서 이 상품의 장점을 한 문장으로 설명한다.\n",
        "3. 모든 키워드를 쓸 필요 없이, 자연스러운 간결한 문장 하나로 완성한다.\n",
        "4. 한글로 쓴다.\n",
        "5. 객관적인 시선으로 쓴다.\n",
        "'''.format('세제')\n",
        "\n",
        "keyword = []\n",
        "for i in topic_idxs:\n",
        "    for w, p in model.get_topic(i):\n",
        "        keyword.append(w)\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": ' '.join(keyword)+prompt}\n",
        "    ]\n",
        ")\n",
        "print(' '.join(keyword)+prompt)\n",
        "print(completion.choices[0].message['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ooVBiNeqRpn",
        "outputId": "ca732ed5-51ff-423c-a194-e8e9a0fe6536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 3946, done.\u001b[K\n",
            "remote: Counting objects: 100% (974/974), done.\u001b[K\n",
            "remote: Compressing objects: 100% (153/153), done.\u001b[K\n",
            "remote: Total 3946 (delta 872), reused 831 (delta 820), pack-reused 2972\u001b[K\n",
            "Receiving objects: 100% (3946/3946), 8.25 MiB | 12.04 MiB/s, done.\n",
            "Resolving deltas: 100% (2510/2510), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_9EO3sPqtlS",
        "outputId": "97ed3312-3e27-486d-81a9-f5200a84ce7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./fastText\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext==0.9.2)\n",
            "  Using cached pybind11-2.10.4-py3-none-any.whl (222 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (1.22.4)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4384288 sha256=c34d71a12ba20285f6ed2376122cdded04f964b73dafaaca06346213f5f643f2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-x0dobfu9/wheels/8b/05/af/3cfae069d904597d44b309c956601b611bdf8967bcbe968903\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.10.4\n"
          ]
        }
      ],
      "source": [
        "!sudo sudo pip install fastText/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM_w3iHarwjf",
        "outputId": "f84c57e5-0128-43ea-e9bf-7f2d8b04d261"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ko.300.bin.gz\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import fasttext.util\n",
        "\n",
        "fasttext.util.download_model('ko', if_exists='ignore')\n",
        "ft = fasttext.load_model('cc.ko.300.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCh3s9Mzzb8D"
      },
      "outputs": [],
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    if norm(a) == 0 or norm(b) == 0:\n",
        "        return 0\n",
        "    return dot(a, b)/(norm(a)*norm(b))\n",
        "\n",
        "# res = 0\n",
        "# for k in range(n_topic-1):\n",
        "#     words = [w for w, p in model.get_topic(k)]\n",
        "\n",
        "#     for i in range(9):\n",
        "#         for j in range(i+1, 10):\n",
        "#             res += cos_sim(ft.get_word_vector(words[i]), ft.get_word_vector(words[j]))\n",
        "# print(res/(n_topic-1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i696ZoCNyNN",
        "outputId": "a86f69fb-560e-4be6-b5dd-5ebf97e7c289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/beomi_KcELECTRA-base-v2022. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/beomi_KcELECTRA-base-v2022 were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 4.241765892133117\n",
            "3 8.154661545529962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/beomi_KcELECTRA-base-v2022. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/beomi_KcELECTRA-base-v2022 were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 2.3152180574834347\n",
            "4 4.855229480812947\n",
            "4 5.346854546417792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/beomi_KcELECTRA-base-v2022. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/beomi_KcELECTRA-base-v2022 were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 2.591566505841911\n",
            "5 4.736353600630537\n",
            "5 6.817301756935194\n",
            "5 7.186020556138828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/beomi_KcELECTRA-base-v2022. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/beomi_KcELECTRA-base-v2022 were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 1.9635285008698702\n",
            "6 3.523007851652801\n",
            "6 5.187766376696527\n",
            "6 5.482741416059435\n",
            "6 6.011987770162523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/beomi_KcELECTRA-base-v2022. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/beomi_KcELECTRA-base-v2022 were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 1.0838049817830324\n",
            "7 2.462786504533142\n",
            "7 4.09501750410224\n",
            "7 5.6272410053449375\n",
            "7 7.014539776214709\n",
            "7 7.260352309017132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/beomi_KcELECTRA-base-v2022. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/beomi_KcELECTRA-base-v2022 were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 1.2508930782122272\n",
            "8 2.3741862696728537\n",
            "8 3.180739665537008\n",
            "8 4.695698940993419\n",
            "8 5.90427282838417\n",
            "8 6.228534357489219\n",
            "8 7.918843513886843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/beomi_KcELECTRA-base-v2022. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/beomi_KcELECTRA-base-v2022 were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 0.9489454491995275\n",
            "9 2.061039219610393\n",
            "9 3.4760031728073955\n",
            "9 4.116148229804821\n",
            "9 5.173650381271727\n",
            "9 6.162193275114987\n",
            "9 6.445922113081906\n",
            "9 6.874456827586982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/beomi_KcELECTRA-base-v2022. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/beomi_KcELECTRA-base-v2022 were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 0.8435070659551356\n",
            "10 1.7912773004629545\n",
            "10 2.9951573977660804\n",
            "10 4.016639731927878\n",
            "10 4.941505579174393\n",
            "10 5.193708990700543\n",
            "10 6.508393890120917\n",
            "10 6.8893136363476515\n",
            "10 7.183339388627145\n"
          ]
        }
      ],
      "source": [
        "max_ntopic = 3\n",
        "max_sim = 0\n",
        "for nt in range(3, 11):\n",
        "    model = BERTopic(embedding_model=\"beomi/KcELECTRA-base-v2022\",\n",
        "                 representation_model=representation_model,\n",
        "                 ctfidf_model=ctfidf_model,\n",
        "                 seed_topic_list=seed_li,\n",
        "                 vectorizer_model=vectorizer,\n",
        "                 nr_topics=nt,\n",
        "                 top_n_words=10,\n",
        "                 calculate_probabilities=True)\n",
        "\n",
        "    topics, probs = model.fit_transform(preprocessed_documents)\n",
        "    res = 0\n",
        "    for k in range(nt-1):\n",
        "        try:\n",
        "            words = [w for w, p in model.get_topic(k)]\n",
        "\n",
        "            for i in range(9):\n",
        "                for j in range(i+1, 10):\n",
        "                    res += cos_sim(ft.get_word_vector(words[i]), ft.get_word_vector(words[j]))\n",
        "        except:\n",
        "            print('some topics are not generated!')\n",
        "        print(nt, res/(nt-1))\n",
        "        if max_sim < res/(nt-1):\n",
        "            max_sim = res/(nt-1)\n",
        "            max_ntopic = nt\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "s = pd.Series([7.613388883764856, 7.7239836708176886, 7.50977203424554, 5.769394177757204, 6.1462348337906105, 6.746630356040051, 6.292013147147372, 7.278624294189892, 6.761026290175505, 5.334416396513751, 6.402406605964643, 6.150669517734339, 6.961633891054329])\n",
        "s.plot.bar()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "G92lI1SablJq",
        "outputId": "26fc6803-79a9-432c-c858-ebb0a69d9622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()"
      ],
      "metadata": {
        "id": "2eBwKv8idp6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lUD41nOXQTL",
        "outputId": "262ea419-671b-4229-8999-5a282d83c26f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 8.154661545529962\n"
          ]
        }
      ],
      "source": [
        "print(max_ntopic, max_sim)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}